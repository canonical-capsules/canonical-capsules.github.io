<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap"
      rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
  	<title>Canonical Capsules: Self-Supervised Capsules in Canonical Pose</title>
      <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
          if you update and want to force Facebook to re-scrape. -->
  	<meta property="og:image" content="./resources/teaser.gif"/>
  	<meta property="og:title" content="Canonical Capsules @ NeurIPS2021" />
  	<meta property="og:description" content="A self-supervised capsule architecture that canonicalizes data while simultaneously decomposing point clouds into parts to perform unsupervised representation learning. " />
    <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
        if you update and want to force Twitter to re-scrape. -->
    <meta property="twitter:card"          content="summary" />
    <meta property="twitter:title"         content="Canonical Capsules @ NeurIPS2021" />
    <meta property="twitter:description"   content="A self-supervised capsule architecture that canonicalizes data while simultaneously decomposing point clouds into parts to perform unsupervised representation learning." />
    <meta property="twitter:image"         content="./resources/teaser.gif" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Add your Google Analytics tag here -->
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>

</head>

<body>
<div class="container">
    <div class="title">
        Canonical Capsules: Self-Supervised Capsules in Canonical Pose
    </div>

    <div class="venue">
        Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)
    </div>

    <br><br>

    <div class="author">
        <a href="http://wsunid.github.io" target="_blank">Weiwei Sun</a> <sup>1 4 *</sup> 
    </div>
    <div class="author">
        <a href="https://taiya.github.io" target="_blank">Andrea Tagliasacchi</a> <sup>2 3 *</sup>
    </div>
    <div class="author">
        <a href="https://boyangdeng.com" target="_blank">Boyang Deng</a> <sup>3</sup>
    </div>
    <div class="author">
        <a href="https://scholar.google.ca/citations?user=l8wQ39EAAAAJ&hl=en" target="_blank">Sara Sabour</a> <sup>2 3</sup>  
    </div>
    <div class="author">
        <a href="https://scholar.google.com/citations?user=u6IqTfoAAAAJ&hl=en" target="_blank">Soroosh Yazdani</a> <sup>3</sup> 
    </div>
    <div class="author">
        <a href="https://www.cs.toronto.edu/~hinton" target="_blank">Geoffrey Hinton</a> <sup>2 3</sup> 
    </div>
    <div class="author">
        <a href="https://www.cs.ubc.ca/~kmyi" target="_blank">Kwang Moo Yi</a> <sup>1 4</sup> 
    </div>

    <br><br>

    <div class="affiliation"><sup>1</sup> University of British Columbia </div>
    <div class="affiliation"><sup>2</sup> University of Toronto  </div>
    <div class="affiliation"><sup>3</sup> Google Research  </div>
    <div class="affiliation"><sup>4</sup> University of Victoria </div> 
    <div class="affiliation"><sup>*</sup> Equal contributions</div> 

    <br><br>

    <div class="links"><a href="resources/CanonicalCapsulesNeurIPS2021.pdf">[Paper]</a></div>
    <div class="links"><a href="https://youtu.be/tUQJV2W7Z8g">[Video]</a></div>
    <div class="links"><a href="https://github.com/canonical-capsules/canonical-capsules">[Code]</a></div>
    <div class="links"><a href="https://arxiv.org/abs/2012.04718">[ArXiv]</a></div>

    <br><br><br>

    <img style="width: 80%;" src="resources/teaser.gif" alt="Teaser figure."/>
    <br><br>

    <!-- <img style="width: 80%;" src="./resources/teaser.jpg" alt="Teaser figure."/> -->
    <br>
    <p style="width: 80%;"> 
        <b>TL;DR:</b> A self-supervised capsule architecture that canonicalizes data while simultaneously decomposing point clouds into parts to perform unsupervised representation learning.
    </p>

    <br><br>
    <hr>

    <h1>Paper</h1>
    <div class="paper-thumbnail">
        <a href="https://arxiv.org/abs/2012.04718">
            <img class="layered-paper-big" width="100%" src="./resources/paper.png" alt="Paper thumbnail"/>
        </a>
    </div>
    <div class="paper-info">
        <h3>Canonical Capsules: Self-Supervised Capsules in Canonical Pose</h3>
        <p>Weiwei Sun, Andrea Tagliasacchi, Boyang Deng, Sara Sabour, Soroosh Yazdani, Geoffrey Hinton, Kwang Moo Yi</p>
        <p>In Conference, NeurIPS 2021.</p>
        <pre><code>@InProceedings{sun2021canonicalcapsules,
title = {Canonical Capsules: Self-Supervised Capsules in Canonical Pose},
author = {Weiwei Sun, Andrea Tagliasacchi, Boyang Deng, Sara Sabour, Soroosh Yazdani, Geoffrey Hinton, Kwang Moo Yi},
booktitle = {Neural Information Processing Systems},
year = {2021}}
</code></pre>
    </div>

    <br><br>
    <hr>

    <h1>Abstract</h1>
    <p style="width: 80%;">
        We propose an unsupervised capsule architecture for 3D point clouds.
		We compute capsule decompositions of objects through permutation-equivariant attention, 
		and self-supervise the process by training with pairs of randomly rotated objects. 
		Our key idea is to aggregate the attention masks into semantic keypoints, and use these to supervise a decomposition that satisfies the capsule invariance/equivariance properties. 
		This not only enables the training of a semantically consistent decomposition, 
		but also allows us to learn a canonicalization operation that enables object-centric reasoning. 
		To train our neural network we require neither classification labels nor manually-aligned training datasets. 
		Yet, by learning an object-centric representation in a self-supervised manner, 
		our method outperforms the state-of-the-art on 3D point cloud reconstruction, canonicalization, and unsupervised classification.
    </p>

    <br><br>
    <hr>

    <h1>Presentation Video</h1>
    <div class="video-container">
        <iframe src="https://www.youtube.com/embed/tUQJV2W7Z8g" frameBorder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
    </div>

    <br><br>
    <!-- <hr>

    <h1>Method Overview</h1>
    <img style="width: 80%;" src="./resources/method.png"
         alt="Method overview figure"/>
    <br>
    <a class="links" href="https://github.com/canonical-capsules/canonical-capsules">[Code]</a> -->

    <br><br>
    <hr>

    <h1>Results</h1>

    <p style="width: 80%;"> We show qualitative highlights, where we decompose 3D point
        clouds and auto-encode them using Canonical Capsules. We color each
        Canonical Capsule with a unique colour, and similarly color "patches"
        from the reconstruction heads of 3D-PointCapsNet and AtlasNetV2.
        Canonical Capsules provide semantically consistent decomposition that
        is aligned in the canonical frame, leading to improved reconstruction
        quality and unsupervised classification performance.
    </p> <br><br>

    <table class="tbl_video">
        <tr>
            <td colspan="6" style="background-color: #eeeeee; font-size: 20px;">
                Results with the single-category Canonical Capsules
            </td>
        </tr>
        <tr>
            <td colspan="6">
                <video width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                    <source src="resources/results/single.mp4" type="video/mp4">
                </video>
            </td>
        </tr>
        <tr>
            <td width=16.66% style="font-size: 18px;"> Input </td>
            <td width=16.66% style="font-size: 18px;"> Decomposition </td>
            <td width=16.66% style="font-size: 18px;"> <i>Ours</i> reconstruction in canonical frame - not a still image! </td>
            <td width=16.66% style="font-size: 18px;"> <i>Ours</i> reconstruction in input frame</td>
            <td width=16.66% style="font-size: 18px;"> 3D-PointCapsNet reconstruction </td>
            <td width=16.66% style="font-size: 18px;"> AtlasNetV2 reconstruction </td>
        </tr>
    </table>
    <br>
    <table class="tbl_video">
        <tr>
            <td colspan="6" style="background-color: #eeeeee; font-size: 20px;">
                Results with the multi-category Canonical Capsules
            </td>
        </tr>
        <tr>
            <td colspan="6">
                <video width="100%" loop autoplay muted>
                    <source src="resources/results/multiclass.mp4" type="video/mp4">
                </video>
            </td>
        </tr>
        <tr>
            <td width=16.66% style="font-size: 18px;"> Input </td>
            <td width=16.66% style="font-size: 18px;"> Decomposition </td>
            <td width=16.66% style="font-size: 18px;"> <i>Ours</i> reconstruction in canonical frame </td>
            <td width=16.66% style="font-size: 18px;"> <i>Ours</i> reconstruction in input frame</td>
            <td width=16.66% style="font-size: 18px;"> 3D-PointCapsNet reconstruction </td>
            <td width=16.66% style="font-size: 18px;"> AtlasNetV2 reconstruction </td>
        </tr>
    </table>


    

    <br><br>
    <hr>

    <h1>Acknowledgements</h1> 
    <p style="width: 80%;">
        This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant, NSERC Collaborative Research and Development Grant, Google, Compute Canada, and Advanced Research Computing at the University of British Columbia.
        <br><br>
        This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful project</a>, and inherits the modifications made by <a href="https://github.com/elliottwu/webpage-template">Shangzhe Wu</a>.
        The code can be found <a href="https://github.com/canonical-capsules/canonical-capsules.github.io">here</a>.
    </p>

    <br><br>
</div>

</body>

</html>
